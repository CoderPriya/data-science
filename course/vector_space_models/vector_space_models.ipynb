{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Vector Space Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "Tokenize a string into linguistic tokens:\n",
    "\n",
    "```python\n",
    "\"I'm Dr. Jinho Choi. Call me Jinho.\"\n",
    "['I', \"'m\", 'Dr.', 'Jinho', 'Choi', '.', 'Call', 'me', 'Jinho', '.']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizer in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from typing import Union, List, Set\n",
    "from tokenizer import tokenize\n",
    "\n",
    "# if flag = 0, return a list\n",
    "def tok(text: str, flag: int=0) -> Union[List[str], Set[str]]:\n",
    "    \"\"\"\n",
    "    @return if flag is 0, a list of tokens; otherwise, a set of tokens.\n",
    "    \"\"\"\n",
    "    if flag == 0:\n",
    "        return [t.txt for t in tokenize(text) if t.txt]\n",
    "    else:\n",
    "        return {t.txt for t in tokenize(text) if t.txt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm\", 'Dr.', 'Jinho', 'Choi', '.', 'Call', 'me', 'Jinho', '.']\n",
      "{'Choi', 'Call', '.', 'Dr.', 'me', 'Jinho', \"I'm\"}\n"
     ]
    }
   ],
   "source": [
    "text = \"I'm Dr. Jinho Choi. Call me Jinho.\"\n",
    "print(tok(text))\n",
    "print(tok(text, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Update the `tok` function such that it returns:\n",
    "* if `flag` is `0`, a list of tokens\n",
    "* if `flag` is `1`, a set of tokens\n",
    "* otherwise, a dictionary where the key is a token and the value is its count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from collections import Counter\n",
    "\n",
    "def tok(text: str, flag: int=2) -> Union[List[str], Set[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    @return if flag is 0, a list of tokens; if flag is 1, a set of tokens; otherwise, a dictionary where the key is a token and the value is its count.\n",
    "    \"\"\"\n",
    "    if flag == 0:\n",
    "        return [t.txt for t in tokenize(text) if t.txt]\n",
    "    elif flag == 1:\n",
    "        return {t.txt for t in tokenize(text) if t.txt}\n",
    "    else:\n",
    "        return Counter([t.txt for t in tokenize(text) if t.txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Jinho': 2, '.': 2, \"I'm\": 1, 'Dr.': 1, 'Choi': 1, 'Call': 1, 'me': 1})\n"
     ]
    }
   ],
   "source": [
    "print(tok(text, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "Read a file and return a dictionary of (token, value) pairs in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(filename: str) -> Dict[str, int]:\n",
    "    fin = open(filename)\n",
    "    return tok(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 26\n",
      ", 25\n",
      "and 16\n",
      "of 14\n",
      ". 14\n",
      "in 12\n",
      "was 7\n",
      "He 7\n",
      "- 6\n",
      "his 6\n"
     ]
    }
   ],
   "source": [
    "bow = bag_of_words('res/george_washington.txt')\n",
    "for k, v in sorted(bow.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TF-IDF\n",
    "\n",
    "$$\\mathrm{tf}\\cdot\\mathrm{idf}_{w,d} = \\mathrm{tf}_{w,d} \\cdot \\log\\frac{|D|}{\\mathrm{df}_w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "al = bag_of_words('res/abraham_lincoln.txt')\n",
    "fr = bag_of_words('res/franklin_roosevelt.txt')\n",
    "gw = bag_of_words('res/george_washington.txt')\n",
    "kb = bag_of_words('res/kobe_bryant.txt')\n",
    "lj = bag_of_words('res/lebron_james.txt')\n",
    "mj = bag_of_words('res/michael_jordan.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that takes a list of bag_of_words and returns a dictionary whose key is a token and the value is its document frequency.\n",
    "\n",
    "```python\n",
    "def doc_freq(*bow_list: Dict[str, int]) -> Dict[str, int]:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def doc_freq(*bow_list: Dict[str, int]) -> Dict[str, int]:\n",
    "    '''\n",
    "    @return a dictionary whose key is a token and the value is its document frequency.\n",
    "    '''\n",
    "    d = {}\n",
    "    \n",
    "    for bow in bow_list:\n",
    "        for token in bow:\n",
    "            d[token] = d.get(token, 0) + 1\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "df = doc_freq(al, fr, gw, kb, lj, mj)\n",
    "print(df['the'])\n",
    "print(df['NBA'])\n",
    "print(df['president'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tfidf(bow: Dict[str, int], df: Dict[str, int]) -> Dict[str, float]:\n",
    "    '''\n",
    "    @return a dictionary where the key is a token and the value is its TF-IDF score.\n",
    "    '''\n",
    "    return {token: tf * math.log(len(df) / df[token]) for token, tf in bow.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 39\n",
      ", 34\n",
      ". 25\n",
      "in 20\n",
      "and 20\n",
      "of 20\n",
      "- 14\n",
      "Jordan 13\n",
      "NBA 13\n",
      "a 12\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(mj.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 205.4799589740981\n",
      ", 179.13637449023938\n",
      ". 131.71792241929364\n",
      "in 105.37433793543492\n",
      "and 105.37433793543492\n",
      "of 105.37433793543492\n",
      "Jordan 91.78619275799741\n",
      "NBA 77.50423300531199\n",
      "- 73.76203655480444\n",
      "a 63.224602761260954\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(tfidf(mj, df).items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercie\n",
    "\n",
    "Modify the `tfidf` function that returns more meaningful scores given this small set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tfidf2(bow: Dict[str, int], df: Dict[str, int]) -> Dict[str, float]:\n",
    "    '''\n",
    "    @return a dictionary where the key is a token and the value is its TF-IDF score.\n",
    "    '''\n",
    "    return {token: tf / df[token]**2 for token, tf in bow.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan 13.0\n",
      "Bulls 4.0\n",
      "titles 3.0\n",
      "Michael 2.0\n",
      "Wizards 2.0\n",
      "owner 2.0\n",
      "Smith 2.0\n",
      "Air 2.0\n",
      "1992 2.0\n",
      "1993 2.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(tfidf2(mj, df).items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "$$\n",
    "cos(A, B) = \\frac{\\sum_{i=1}^n A_i B_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\sqrt{\\sum_{i=1}^n B_i^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cos(A: Dict[str, float], B: Dict[str, float]) -> float:\n",
    "    num = sum([a * B.get(token, 0) for token, a in A.items()])\n",
    "    den = math.sqrt(sum([v**2 for v in A.values()])) * math.sqrt(sum([v**2 for v in B.values()]))\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AL    FR    GW    KB    LJ    MJ\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-be8f8c3720da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'     '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'    '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_a\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'%4.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "labels = ['AL', 'FR', 'GW', 'KB', 'LJ', 'MJ']\n",
    "docs_raw = [al, fr, gw, kb, lj, mj]\n",
    "\n",
    "print('     '+'    '.join(labels))\n",
    "for i, doc_a in enumerate(docs_raw):\n",
    "    s = ['%4.2f' % cos(doc_a, doc_b) for doc_b in docs]\n",
    "    print(labels[i]+'  '+'  '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AL    FR    GW    KB    LJ    MJ\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8d862b35ce2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'     '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'    '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_a\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'%4.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs_tfidf = [tfidf(doc, df) for doc in docs_raw]\n",
    "\n",
    "print('     '+'    '.join(labels))\n",
    "for i, doc_a in enumerate(docs_tfidf):\n",
    "    s = ['%4.2f' % cos(doc_a, doc_b) for doc_b in docs]\n",
    "    print(labels[i]+'  '+'  '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AL    FR    GW    KB    LJ    MJ\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-09c0286fadba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'     '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'    '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_a\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_tfidf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'%4.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs_tfidf2 = [tfidf2(doc, df) for doc in docs_raw]\n",
    "\n",
    "print('     '+'    '.join(labels))\n",
    "for i, doc_a in enumerate(docs_tfidf2):\n",
    "    s = ['%4.2f' % cos(doc_a, doc_b) for doc_b in docs]\n",
    "    print(labels[i]+'  '+'  '.join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def term_index(df: Dict[str, int]) -> Dict[str, int]:\n",
    "    return {k: i for i, k in enumerate(df.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ti = term_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def doc_to_vec(tfidf, ti):\n",
    "    n = np.zeros(len(ti))\n",
    "    for token, score in tfidf.items():\n",
    "        n[ti[token]] = score\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.array([doc_to_vec(doc, ti) for doc in docs_tfidf])\n",
    "kmeans = KMeans(n_clusters=2).fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "aggl = AgglomerativeClustering(affinity='cosine', linkage='complete').fit(X)\n",
    "aggl.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
